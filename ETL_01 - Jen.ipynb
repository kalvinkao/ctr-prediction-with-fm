{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project ETL for Development Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "#mllib.linalg library \n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "#PWD = !pwd\n",
    "#PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"w261FinalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`REMINDER:`__ If you are running this notebook on the course docker container, you can monitor the progress of your jobs using the Spark UI at: http://localhost:4040/jobs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_trainRDD = sc.textFile('data/train.txt')\n",
    "original_testRDD = sc.textFile('data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[521] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the seed for a different sample\n",
    "sampleRDD1, sampleRDD2 = original_trainRDD.randomSplit([0.9999,0.0001], seed = 1)\n",
    "sampleRDD2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sample contains 4478 rows.\n"
     ]
    }
   ],
   "source": [
    "nrow = sampleRDD2.count()\n",
    "print(\"This sample contains\", str(nrow), \"rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sampleRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t18\\t09ca0b81\\t09e68b86\\t86c4b829\\te3d0459f\\t25c83c98\\t\\t7227c706\\t0b153874\\ta73ee510\\t305a0646\\t9625b211\\t997a695a\\tdccbd94b\\t07d13a8f\\t36721ddc\\tc0b906bb\\te5ba7672\\t5aed7436\\t21ddcdc9\\ta458ea53\\t0cbbcc92\\t\\t32c7478e\\t0174dd24\\t3d2bedd7\\td8ecbc17',\n",
       " '0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t18\\tbe589b51\\t8e465f4d\\t35d889dd\\t5e5e218f\\t25c83c98\\t6f6d9be8\\t5732a3f8\\t0b153874\\ta73ee510\\ta1680317\\td70e2491\\t575bb5c9\\t2b9f0754\\t07d13a8f\\te815112f\\t85a05c1a\\td4bb7bd8\\tf2becb37\\t\\t\\tfe89e74a\\t\\t32c7478e\\tbaf42944\\t\\t']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleRDD2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t18\\t09ca0b81\\t09e68b86\\t86c4b829\\te3d0459f\\t25c83c98\\t\\t7227c706\\t0b153874\\ta73ee510\\t305a0646\\t9625b211\\t997a695a\\tdccbd94b\\t07d13a8f\\t36721ddc\\tc0b906bb\\te5ba7672\\t5aed7436\\t21ddcdc9\\ta458ea53\\t0cbbcc92\\t\\t32c7478e\\t0174dd24\\t3d2bedd7\\td8ecbc17'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleRDD2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  helper function to normalize the data \n",
    "def normalize(dataRDD):\n",
    "    \"\"\"\n",
    "    Scale and center data round mean of each feature.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "    Returns:\n",
    "        normedRDD - records are tuples of (features_array, y)\n",
    "    \"\"\"\n",
    "      \n",
    "    numericalRDD = dataRDD.map(lambda x: list(x[:13])).cache()\n",
    "    \n",
    "    def remove_na(col):\n",
    "        '''\n",
    "        we needed a column wise calc of mean and std. To do this we had to remove NaN \n",
    "        while maintaining the position of the number in the RDD so its emited as an key\n",
    "        '''\n",
    "        #good_stuff, id = col[0], col[1]\n",
    "        for i in range(0,len(col)):\n",
    "            if (col[i] != '\\t') and (col[i] != '-'):\n",
    "                yield(i,int(col[i]))\n",
    "        \n",
    "    featureSums = numericalRDD.flatMap(lambda x: remove_na(x)) \\\n",
    "                               .reduceByKey(lambda a, b: (a + b)).collect()\n",
    "    featureCount = numericalRDD.flatMap(lambda x: remove_na(x)).countByKey()\n",
    "    \n",
    "    #calc mean for each of the 13 columns \n",
    "    #featureSums is a list and featureCount is a dictionary, so some matching needed to be completed\n",
    "    means_dict = dict()\n",
    "    for j in range(0,len(featureCount)+1):\n",
    "        for k in range(0,12):\n",
    "            if featureSums[k][0] == j:\n",
    "                cur_col_sum = featureSums[k][1]\n",
    "        if j not in featureCount.keys():\n",
    "            next\n",
    "        else:\n",
    "            cur_col_mean = cur_col_sum / featureCount[j]\n",
    "            means_dict[j] = cur_col_mean\n",
    "           # print(j, cur_col_mean)\n",
    "        \n",
    "    mean_dict1 = sc.broadcast(means_dict)\n",
    "    #print(mean_dict1.value)\n",
    "    \n",
    "    def calc_std(line):\n",
    "        key,value = line[0],line[1]\n",
    "        #yield((key, mean_dict1.value[key]))\n",
    "        individ_deviation = (value - mean_dict1.value[key])**2\n",
    "        yield((key,individ_deviation))\n",
    "    \n",
    "    \n",
    "    featureStd = numericalRDD.flatMap(lambda x: remove_na(x)) \\\n",
    "                            .flatMap(lambda x: calc_std(x)) \\\n",
    "                            .reduceByKey(lambda a, b: (a + b)).collect()\n",
    "    #calc std for each of the 13 columns; test = total error across all observations by key\n",
    "    std_dict = dict()\n",
    "    for j in range(0,len(featureCount)+1):\n",
    "        if j not in featureCount.keys():\n",
    "            next\n",
    "        else:\n",
    "            for k in range(0,12):\n",
    "                if featureStd[k][0] == j:\n",
    "                    cur_col_sum = featureStd[k][1]\n",
    "            cur_col_mean = np.sqrt(cur_col_sum / featureCount[j])\n",
    "            std_dict[j] = cur_col_mean\n",
    "    std_dict1 = sc.broadcast(std_dict)\n",
    "    #print(\"std_dict\", std_dict)\n",
    "    \n",
    "    def apply_transformation(col):\n",
    "        new_row =[]\n",
    "        for i in range(0,len(col)):\n",
    "            if (col[i] == '\\t') or (col[i] == '-'):\n",
    "                new_row.append(col[i])\n",
    "            else:\n",
    "                key,value = i,int(col[i])\n",
    "                feature_mean = mean_dict1.value[key]\n",
    "                feature_std = std_dict1.value[key]\n",
    "                new_value = round(((value-feature_mean)/feature_std),2)\n",
    "                new_row.append(new_value)\n",
    "        return(new_row)\n",
    "    \n",
    "    normedRDD = numericalRDD.map(lambda x: apply_transformation(x))\n",
    "    \n",
    "    #print(normedRDD.collect())\n",
    "    \n",
    "    return(normedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "normedRDD = normalize(sampleRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.59, \\t, \\t, 0.62, \\t, 0.62, -1.32, \\t, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.59, \\t, \\t, -0.61, -0.24, \\t, -0.56, -1.32...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.69, \\t, \\t, -0.61, \\t, -0.86, \\t, \\t, 2.23,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.59, \\t, 3.04, \\t, -0.63, 1.35, \\t, \\t, -0....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.69, \\t, 2.09, \\t, -0.63, \\t, 1.36, 1.03, \\t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  [-0.59, \\t, \\t, 0.62, \\t, 0.62, -1.32, \\t, -0....  0\n",
       "1  [-0.59, \\t, \\t, -0.61, -0.24, \\t, -0.56, -1.32...  1\n",
       "2  [1.69, \\t, \\t, -0.61, \\t, -0.86, \\t, \\t, 2.23,...  2\n",
       "3  [-0.59, \\t, 3.04, \\t, -0.63, 1.35, \\t, \\t, -0....  3\n",
       "4  [1.69, \\t, 2.09, \\t, -0.63, \\t, 1.36, 1.03, \\t...  4"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normedRDD3 = pd.DataFrame(normedRDD.zipWithIndex().collect())\n",
    "#normedRDD3.columns = ['a', 'b']\n",
    "normedRDD3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRDD3 = sampleRDD2.zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...  0\n",
       "1  0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...  1\n",
       "2  1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...  2\n",
       "3  0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...  3\n",
       "4  1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...  4"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleRDD3 = pd.DataFrame(sampleRDD3)\n",
    "sampleRDD3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   a  b\n",
       "0  0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...  0\n",
       "1  0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...  1\n",
       "2  1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...  2\n",
       "3  0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...  3\n",
       "4  1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...  4"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sampleRDD4 = pd.DataFrame(sampleRDD3)\n",
    "sampleRDD3.columns = ['a', 'b']\n",
    "sampleRDD3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.59, \\t, \\t, 0.62, \\t, 0.62, -1.32, \\t, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.59, \\t, \\t, -0.61, -0.24, \\t, -0.56, -1.32...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.69, \\t, \\t, -0.61, \\t, -0.86, \\t, \\t, 2.23,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.59, \\t, 3.04, \\t, -0.63, 1.35, \\t, \\t, -0....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[1.69, \\t, 2.09, \\t, -0.63, \\t, 1.36, 1.03, \\t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   a  b  \\\n",
       "0  0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t...  0   \n",
       "1  0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t...  1   \n",
       "2  1\\t\\t1\\t1\\t\\t993\\t\\t0\\t1\\t2\\t\\t0\\t\\t\\t5a9ed9b0...  2   \n",
       "3  0\\t8\\t17\\t\\t2\\t622\\t22\\t79\\t21\\t557\\t1\\t9\\t0\\t...  3   \n",
       "4  1\\t6\\t1\\t76\\t5\\t7\\t0\\t30\\t4\\t5\\t1\\t6\\t\\t0\\t68f...  4   \n",
       "\n",
       "                                                   0  1  \n",
       "0  [-0.59, \\t, \\t, 0.62, \\t, 0.62, -1.32, \\t, -0....  0  \n",
       "1  [-0.59, \\t, \\t, -0.61, -0.24, \\t, -0.56, -1.32...  1  \n",
       "2  [1.69, \\t, \\t, -0.61, \\t, -0.86, \\t, \\t, 2.23,...  2  \n",
       "3  [-0.59, \\t, 3.04, \\t, -0.63, 1.35, \\t, \\t, -0....  3  \n",
       "4  [1.69, \\t, 2.09, \\t, -0.63, \\t, 1.36, 1.03, \\t...  4  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = sampleRDD4.join(normedRDD3,on='b')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2 =  sc.parallelize(merged.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['0\\t\\t4\\t50\\t18\\t3339\\t20\\t26\\t17\\t133\\t\\t2\\t\\t18\\t09ca0b81\\t09e68b86\\t86c4b829\\te3d0459f\\t25c83c98\\t\\t7227c706\\t0b153874\\ta73ee510\\t305a0646\\t9625b211\\t997a695a\\tdccbd94b\\t07d13a8f\\t36721ddc\\tc0b906bb\\te5ba7672\\t5aed7436\\t21ddcdc9\\ta458ea53\\t0cbbcc92\\t\\t32c7478e\\t0174dd24\\t3d2bedd7\\td8ecbc17',\n",
       "        0,\n",
       "        list([-0.59, '\\t', '\\t', 0.62, '\\t', 0.62, -1.32, '\\t', -0.93, 1.81, '\\t', -0.3, -0.29]),\n",
       "        0], dtype=object),\n",
       " array(['0\\t\\t12\\t20\\t18\\t30445\\t82\\t0\\t18\\t53\\t\\t0\\t\\t18\\tbe589b51\\t8e465f4d\\t35d889dd\\t5e5e218f\\t25c83c98\\t6f6d9be8\\t5732a3f8\\t0b153874\\ta73ee510\\ta1680317\\td70e2491\\t575bb5c9\\t2b9f0754\\t07d13a8f\\te815112f\\t85a05c1a\\td4bb7bd8\\tf2becb37\\t\\t\\tfe89e74a\\t\\t32c7478e\\tbaf42944\\t\\t',\n",
       "        1,\n",
       "        list([-0.59, '\\t', '\\t', -0.61, -0.24, '\\t', -0.56, -1.32, '\\t', -0.89, 1.69, '\\t', -0.29]),\n",
       "        1], dtype=object)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final(line):\n",
    "    'putting things back in the right shape for use in our next function'\n",
    "    new_line =[]\n",
    "    a,b,c,d = line[0],line[1],line[2],line[3]\n",
    "    new_line.append(str(a[0]))\n",
    "    for i in range(0,13):\n",
    "        if c[i]=='\\t':\n",
    "            new_line.append(\"\")\n",
    "        else:\n",
    "            new_line.append(str(c[i]))\n",
    "    for j in range(14,40):\n",
    "        a_new = a.split('\\t')\n",
    "        if a_new[i]=='\\t':\n",
    "            new_line.append(\"\")\n",
    "        else:    \n",
    "            new_line.append(str(a_new[j]))\n",
    "    final_line= \"\\t\".join(new_line)\n",
    "    return(final_line)\n",
    "finalRDD = merged2.map(lambda x: make_final(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t-0.59\\t\\t\\t0.62\\t\\t0.62\\t-1.32\\t\\t-0.93\\t1.81\\t\\t-0.3\\t-0.29\\t09ca0b81\\t09e68b86\\t86c4b829\\te3d0459f\\t25c83c98\\t\\t7227c706\\t0b153874\\ta73ee510\\t305a0646\\t9625b211\\t997a695a\\tdccbd94b\\t07d13a8f\\t36721ddc\\tc0b906bb\\te5ba7672\\t5aed7436\\t21ddcdc9\\ta458ea53\\t0cbbcc92\\t\\t32c7478e\\t0174dd24\\t3d2bedd7\\td8ecbc17',\n",
       " '0\\t-0.59\\t\\t\\t-0.61\\t-0.24\\t\\t-0.56\\t-1.32\\t\\t-0.89\\t1.69\\t\\t-0.29\\tbe589b51\\t8e465f4d\\t35d889dd\\t5e5e218f\\t25c83c98\\t6f6d9be8\\t5732a3f8\\t0b153874\\ta73ee510\\ta1680317\\td70e2491\\t575bb5c9\\t2b9f0754\\t07d13a8f\\te815112f\\t85a05c1a\\td4bb7bd8\\tf2becb37\\t\\t\\tfe89e74a\\t\\t32c7478e\\tbaf42944\\t\\t']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(finalRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put in wide, sparse feature format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCV(line):\n",
    "    \"\"\"\n",
    "    Map record_csv_string --> (features, label)\n",
    "    \"\"\"\n",
    "\n",
    "    # start of categorical features\n",
    "    col_start = 14\n",
    "    \n",
    "    raw_values = line.split('\\t')\n",
    "    label = int(raw_values[0])  ## y variable \n",
    "    \n",
    "    # ignore numerics to start\n",
    "    #numerical_values = list(pd.Series(raw_values[1:14]).apply(pd.to_numeric))\n",
    "    numericals = []\n",
    "    for idx, value in enumerate(raw_values[1:col_start]):\n",
    "        if value != '':\n",
    "            numericals.append('n' + str(idx) + '_' + str(value))\n",
    "            \n",
    "    \n",
    "    categories = []\n",
    "    for idx, value in enumerate(raw_values[col_start:]):\n",
    "        if value != '':\n",
    "            categories.append('c'+ str(idx) + '_' + str(value))\n",
    "\n",
    "    return Row(label=label, raw=numericals + categories)\n",
    "\n",
    "\n",
    "def vectorizeCV(DF):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    cv = CountVectorizer(inputCol=\"raw\", outputCol=\"features\")\n",
    "    \n",
    "    model = cv.fit(DF)\n",
    "    result = model.transform(DF)\n",
    "    \n",
    "    return result\n",
    "parsedDF = sampleRDD2.map(parseCV).toDF().cache()\n",
    "vectorizedDF = vectorizeCV(parsedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                 raw|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[n1_4, n2_50, n3_...|(30946,[0,1,2,4,5...|\n",
      "|    0|[n1_12, n2_20, n3...|(30946,[0,1,2,5,1...|\n",
      "|    1|[n1_1, n2_1, n4_9...|(30946,[0,1,6,7,1...|\n",
      "|    0|[n0_8, n1_17, n3_...|(30946,[0,1,4,12,...|\n",
      "|    1|[n0_6, n1_1, n2_7...|(30946,[0,1,2,4,1...|\n",
      "|    1|[n1_99, n2_1, n3_...|(30946,[1,2,4,10,...|\n",
      "|    0|[n0_3, n1_21, n2_...|(30946,[0,1,4,8,1...|\n",
      "|    0|[n1_2, n2_20, n3_...|(30946,[0,1,3,5,8...|\n",
      "|    0|[n0_0, n1_144, n4...|(30946,[0,2,3,4,5...|\n",
      "|    0|[n1_0, n2_5, n4_3...|(30946,[0,2,3,6,1...|\n",
      "|    0|[n0_0, n1_1, n2_4...|(30946,[0,1,2,3,5...|\n",
      "|    0|[n0_9, n1_5, n2_1...|(30946,[0,2,3,6,9...|\n",
      "|    0|[n1_323, n2_2, n3...|(30946,[1,2,14,16...|\n",
      "|    0|[n0_0, n1_424, n3...|(30946,[0,1,2,4,6...|\n",
      "|    0|[n0_0, n1_13, n2_...|(30946,[0,1,2,5,6...|\n",
      "|    0|[n1_180, n2_6, n3...|(30946,[1,2,8,14,...|\n",
      "|    0|[n1_126, n2_2, n3...|(30946,[0,2,4,6,8...|\n",
      "|    0|[n1_21, n2_3, n3_...|(30946,[1,2,6,10,...|\n",
      "|    1|[n0_16, n1_2, n2_...|(30946,[0,1,4,5,6...|\n",
      "|    0|[n1_213, n2_7, n3...|(30946,[0,2,4,6,8...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#not sure why its 30,946 in the first column...comes out of countvectorizor on spark\n",
    "#https://spark.apache.org/docs/latest/ml-features.html#countvectorizer\n",
    "vectorizedDF = vectorizeCV(parsedDF)\n",
    "vectorizedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                 raw|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[n0_-0.59, n3_0.6...|(25779,[0,1,2,3,5...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[0,1,2,3,6...|\n",
      "|    1|[n0_1.69, n3_-0.6...|(25779,[0,2,7,8,1...|\n",
      "|    0|[n0_-0.59, n2_3.0...|(25779,[0,1,2,5,1...|\n",
      "|    1|[n0_1.69, n2_2.09...|(25779,[0,2,3,5,1...|\n",
      "|    1|[n0_1.69, n3_2.66...|(25779,[2,3,5,10,...|\n",
      "|    0|[n0_-0.59, n2_0.6...|(25779,[0,1,2,5,9...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[0,1,2,4,6...|\n",
      "|    0|[n0_-0.59, n2_-0....|(25779,[0,1,3,4,5...|\n",
      "|    0|[n0_-0.59, n3_-1....|(25779,[0,1,3,4,7...|\n",
      "|    0|[n0_-0.59, n2_-0....|(25779,[0,1,2,3,4...|\n",
      "|    0|[n0_-0.59, n2_3.5...|(25779,[0,1,3,4,7...|\n",
      "|    0|[n0_-0.59, n3_0.2...|(25779,[1,2,3,13,...|\n",
      "|    0|[n0_-0.59, n2_-0....|(25779,[0,1,2,3,5...|\n",
      "|    0|[n0_-0.59, n2_-0....|(25779,[0,1,2,3,6...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[1,2,3,9,1...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[0,1,3,5,7...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[1,2,3,7,1...|\n",
      "|    1|[n0_1.69, n2_-0.2...|(25779,[0,2,5,6,7...|\n",
      "|    0|[n0_-0.59, n3_-0....|(25779,[0,1,3,5,7...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsedDF = finalRDD.map(parseCV).toDF().cache()\n",
    "vectorizedTest = vectorizeCV(parsedDF)\n",
    "#vectorizedTest = vectorizeCV(parsedDF)\n",
    "vectorizedTest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile(\"fm_parallel_sgd.py\")\n",
    "import fm_parallel_sgd as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4478\n",
      "4478\n",
      "Row(label=0, raw=['n1_4', 'n2_50', 'n3_18', 'n4_3339', 'n5_20', 'n6_26', 'n7_17', 'n8_133', 'n10_2', 'n12_18', 'c0_09ca0b81', 'c1_09e68b86', 'c2_86c4b829', 'c3_e3d0459f', 'c4_25c83c98', 'c6_7227c706', 'c7_0b153874', 'c8_a73ee510', 'c9_305a0646', 'c10_9625b211', 'c11_997a695a', 'c12_dccbd94b', 'c13_07d13a8f', 'c14_36721ddc', 'c15_c0b906bb', 'c16_e5ba7672', 'c17_5aed7436', 'c18_21ddcdc9', 'c19_a458ea53', 'c20_0cbbcc92', 'c22_32c7478e', 'c23_0174dd24', 'c24_3d2bedd7', 'c25_d8ecbc17'], features=SparseVector(30946, {0: 1.0, 1: 1.0, 2: 1.0, 4: 1.0, 5: 1.0, 7: 1.0, 10: 1.0, 20: 1.0, 32: 1.0, 122: 1.0, 155: 1.0, 173: 1.0, 214: 1.0, 365: 1.0, 369: 1.0, 495: 1.0, 504: 1.0, 632: 1.0, 635: 1.0, 834: 1.0, 1894: 1.0, 2122: 1.0, 2264: 1.0, 2392: 1.0, 2780: 1.0, 6206: 1.0, 11184: 1.0, 12084: 1.0, 13281: 1.0, 18958: 1.0, 20027: 1.0, 24131: 1.0, 25509: 1.0, 25574: 1.0}))\n",
      "Row(label=0, raw=['n0_-0.59', 'n3_0.62', 'n5_0.62', 'n6_-1.32', 'n8_-0.93', 'n9_1.81', 'n11_-0.3', 'n12_-0.29', 'c0_09ca0b81', 'c1_09e68b86', 'c2_86c4b829', 'c3_e3d0459f', 'c4_25c83c98', 'c6_7227c706', 'c7_0b153874', 'c8_a73ee510', 'c9_305a0646', 'c10_9625b211', 'c11_997a695a', 'c12_dccbd94b', 'c13_07d13a8f', 'c14_36721ddc', 'c15_c0b906bb', 'c16_e5ba7672', 'c17_5aed7436', 'c18_21ddcdc9', 'c19_a458ea53', 'c20_0cbbcc92', 'c22_32c7478e', 'c23_0174dd24', 'c24_3d2bedd7', 'c25_d8ecbc17'], features=SparseVector(25779, {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 5: 1.0, 6: 1.0, 8: 1.0, 10: 1.0, 18: 1.0, 29: 1.0, 57: 1.0, 63: 1.0, 123: 1.0, 147: 1.0, 149: 1.0, 155: 1.0, 157: 1.0, 193: 1.0, 391: 1.0, 458: 1.0, 624: 1.0, 1599: 1.0, 1744: 1.0, 2174: 1.0, 4755: 1.0, 13046: 1.0, 14564: 1.0, 16103: 1.0, 16367: 1.0, 16676: 1.0, 16739: 1.0, 21764: 1.0}))\n"
     ]
    }
   ],
   "source": [
    "print (vectorizedDF.rdd.count())\n",
    "print (vectorizedTest.rdd.count())\n",
    "print (vectorizedDF.rdd.first())\n",
    "print (vectorizedTest.rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter \ttime \ttrain_logl \tval_logl\n",
      "0 \t0 \t0.696670 \t0.696431\n",
      "1 \t1 \t2.835949 \t2.765170\n",
      "2 \t3 \t3.017305 \t2.939728\n",
      "3 \t4 \t2.968775 \t2.891082\n",
      "4 \t6 \t2.943212 \t2.865419\n",
      "5 \t7 \t2.934917 \t2.856944\n",
      "6 \t9 \t2.935350 \t2.857216\n",
      "7 \t10 \t2.941669 \t2.863376\n",
      "8 \t12 \t2.949203 \t2.870824\n",
      "9 \t14 \t2.959387 \t2.880917\n",
      "10 \t15 \t2.969375 \t2.890878\n",
      "Train set: \n",
      "rtv_pr_auc, rtv_auc, logl, mse, accuracy\n",
      "(0.9601969430901022, 0.9838280326055683, 2.9693748527221677, 0.7087952691773113, 0.2556390977443609)\n",
      "Validation set:\n",
      "(0.9266569543807905, 0.9558422354230937, 2.890877994349888, 0.6919755965791868, 0.2750845546786922)\n",
      "time : 18.536879062652588\n"
     ]
    }
   ],
   "source": [
    "temp = time.time()\n",
    "model = fm.trainFM_parallel_sgd (sc, vectorizedTest.rdd, iterations=10, iter_sgd= 10, alpha=0.01, regParam=0.01, factorLength=2,\\\n",
    "                      verbose=True, savingFilename = None, evalTraining=None)\n",
    "print ('time :', time.time()-temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (evaluate(vectorizedTest, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "441px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "827px",
    "left": "0px",
    "right": "1125px",
    "top": "107px",
    "width": "428px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
