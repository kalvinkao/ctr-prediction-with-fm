{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR Prediction using Factorization Machines at Scale\n",
    "## MIDS w261 Final Project\n",
    "## December 12, 2018\n",
    "\n",
    "**Authors**: Colby Carter, Kalvin Kao, Adam Letcher, Jennifer Philippou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to working doc (temp):\n",
    "https://docs.google.com/document/d/1BPxVEwYjh5-z-ZjXoMQVcgFdRSDTYC6WTdbH3Dky0hA/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Purpose    \n",
    "\n",
    "Goal  \n",
    "\n",
    "Questions  \n",
    "\n",
    "Purpose  \n",
    "\n",
    "Performance required  \n",
    "\n",
    "http://labs.criteo.com/2014/09/kaggle-contest-dataset-now-available-academic-use/\n",
    "\n",
    "https://www.kaggle.com/c/criteo-display-ad-challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Factorization Machines    \n",
    "\n",
    "(explanation)  \n",
    "\n",
    "https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FM Equation](FINAL/images/FM_equation_Rendle2010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which the right-hand summands can re-written as the following average of differences between dot products for each factor `k`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FM factor](FINAL/images/FM_factor_Rendle2010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyDataRaw = ['1\\t0\\t5\\t\\t1\\t26\\tcat\\tblue\\t\\tpizza',\n",
    "            '0\\t1\\t10\\t1\\t\\t12\\tdog\\tyellow\\t\\t',\n",
    "            '0\\t0\\t\\t0.5\\t2\\t45\\tdog\\t\\tcar\\tsteak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy data made up of label followed by numeric and categorical features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1', ['0', '5', '', '1', '26', 'cat', 'blue', '', 'pizza']),\n",
       " ('0', ['1', '10', '1', '', '12', 'dog', 'yellow', '', '']),\n",
       " ('0', ['0', '', '0.5', '2', '45', 'dog', '', 'car', 'steak'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse out label and features\n",
    "toyDataParsed = []\n",
    "for row in toyDataRaw:\n",
    "    splitRow = row.split('\\t')\n",
    "    toyDataParsed.append((splitRow[0], splitRow[1:]))\n",
    "    \n",
    "print(\"Toy data made up of label followed by numeric and categorical features:\")\n",
    "toyDataParsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This toy exmaple  contains 3 rows and 9 columns, plus a label in index 0.\n"
     ]
    }
   ],
   "source": [
    "ncol = len(toyDataParsed[0][1])\n",
    "nrow = len(toyDataParsed)\n",
    "print(f'This toy exmaple  contains {nrow} rows and {ncol} columns, plus a label in index 0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an average of 6.67 populated features per observation.\n"
     ]
    }
   ],
   "source": [
    "def avgFeatures(row):\n",
    "    count = 0\n",
    "    feats = row[1][:]\n",
    "    for feat in feats:\n",
    "        if feat != '':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "nonSparse = [avgFeatures(row) for row in toyDataParsed]\n",
    "\n",
    "print(\"There is an average of\", str(round(np.mean(nonSparse),2)), \"populated features per observation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of string-indexed features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1',\n",
       " ['v1=0',\n",
       "  'v2=5',\n",
       "  'v3=NA',\n",
       "  'v4=1',\n",
       "  'v5=26',\n",
       "  'v6=cat',\n",
       "  'v7=blue',\n",
       "  'v8=NA',\n",
       "  'v9=pizza'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binarize\n",
    "def makeString(data):\n",
    "    \"\"\"Get list of features and make them into distinct strings according to column index\"\"\"\n",
    "     #include label for SGD\n",
    "    newData = []\n",
    "    for r, row in enumerate(data):\n",
    "        label = row[0]\n",
    "        id_feats = []\n",
    "        for i, value in enumerate(row[1], 1):\n",
    "            if value=='':\n",
    "                add='NA'\n",
    "            else:\n",
    "                add=value\n",
    "            id_feats.append(\"v\"+str(i)+\"=\"+add)\n",
    "        newData.append((label, id_feats))\n",
    "    \n",
    "    return newData\n",
    "    \n",
    "stringData = makeString(toyDataParsed)\n",
    "print(\"Example of string-indexed features:\")\n",
    "stringData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "['v8=NA', 'v7=NA', 'v1=0', 'v9=steak', 'v3=NA', 'v4=1', 'v4=2', 'v7=blue', 'v5=12', 'v9=NA', 'v2=5', 'v2=NA', 'v4=NA', 'v3=0.5', 'v5=45', 'v8=car', 'v5=26', 'v6=dog', 'v1=1', 'v6=cat', 'v2=10', 'v7=yellow', 'v3=1', 'v9=pizza']\n",
      "\n",
      "One-hot encoded featres (first element is label):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oneHotEncode(data):\n",
    "    \"\"\"turn indexed-string features into one-hot encoded features\"\"\"\n",
    "\n",
    "    setFeats = set()\n",
    "    for row in data:\n",
    "        setFeats.update(row[1])\n",
    "    listFeats = list(setFeats)\n",
    "    print(\"Features:\")\n",
    "    print(listFeats)\n",
    "    newData = np.zeros(shape=(len(data), len(listFeats)+1))\n",
    "\n",
    "    for r, row in enumerate(data):\n",
    "        newData[r][0] = row[0]    #first index is the label\n",
    "        for var in row[1]:\n",
    "            newData[r][listFeats.index(var)+1] = 1\n",
    "            \n",
    "    return newData, len(listFeats)\n",
    "    \n",
    "oneHotData, numFeats = oneHotEncode(stringData)\n",
    "print(\"\\nOne-hot encoded featres (first element is label):\")\n",
    "oneHotData[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Updates using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized weight vector W:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03328396,  0.03109567, -0.00353963,  0.00108691,  0.01301888,\n",
       "         0.00522236,  0.01511192, -0.00106579, -0.00058697,  0.00502548,\n",
       "         0.00981188, -0.00124704,  0.00902628, -0.00041259, -0.00939172,\n",
       "        -0.01471153,  0.02622656, -0.00783223, -0.00401789,  0.00080727,\n",
       "         0.03522305, -0.02387439, -0.00679598, -0.00943945]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model\n",
    "b = 0.0\n",
    "w_vector = np.random.normal(0.0, 0.02, (1, numFeats))\n",
    "k = 2    #number of latent factors\n",
    "V_matrix = np.random.normal(0.0, 0.02, (k, numFeats))   #k factors\n",
    "\n",
    "print(\"Initialized weight vector W:\")\n",
    "w_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logarithmic-loss as our cost function along with the chain rule, we can use the product of the following partial derivatives with loss function's derivative, $(\\hat{p_i} - y_i)$, to estimate gradients by parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FM factor](FINAL/images/FM_partials_Rendle2010.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateGradientToy(record, k, b, w, V):\n",
    "    \"\"\"\n",
    "        Compute the predicted probability AND return the gradients\n",
    "        Args:\n",
    "            record - label followed by binarized feature values\n",
    "        Model:\n",
    "            b - bias term (scalar)\n",
    "            w - linear weight vector (array)\n",
    "            k - number of factors (def=2)\n",
    "            V - factor matrix of size (d dimensions, k=2 factors)\n",
    "        Returns:\n",
    "            pair - ([label, predicted probability], [set of weight vectors in csr_matrix format])\n",
    "    \"\"\"\n",
    "    \n",
    "    label = record[0]\n",
    "    feats = record[1:]\n",
    "    \n",
    "    # calculate P-hat    \n",
    "    # start with linear weight dot product (X dot W)\n",
    "    linear_sum = np.dot(w, feats)\n",
    "\n",
    "    # factor matrix interaction sum\n",
    "    factor_sum = 0.0\n",
    "    lh_factor = [0.0]*k\n",
    "    rh_factor = [0.0]*k\n",
    "    for f in range(0, k):\n",
    "        lh_factor[f] = np.dot(V[f][:], feats)  #KEY--this is used in v_grad matrix below\n",
    "        rh_factor[f] = np.dot(V[f][:]**2, feats**2)\n",
    "        factor_sum += (lh_factor[f]**2 - rh_factor[f])\n",
    "    factor_sum = 0.5 * factor_sum\n",
    "    \n",
    "    y_hat = b + linear_sum + factor_sum\n",
    "    \n",
    "    p_hat = 1.0 / (1 + float(np.exp(-y_hat)))  #logit transformation\n",
    "    \n",
    "    #compute Gradients\n",
    "    b_grad = p_hat - label    #the partial derivative of log-loss function wrt constant beta\n",
    "    \n",
    "    w_grad = b_grad*feats\n",
    "    \n",
    "    v_data = np.array([])\n",
    "    for f in range(0, k):\n",
    "        v_data = np.append(v_data, b_grad*(lh_factor[f]*feats - np.multiply(V[f][:], feats**2)))\n",
    "    v_grad = np.reshape(v_data, newshape=(k, V.shape[1]))\n",
    "    \n",
    "    return ([label, p_hat], [b_grad, w_grad, v_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Label, predicted probability), [beta, w vector, V matrix]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0, 0.5024168636288922],\n",
       " [-0.49758313637110785,\n",
       "  array([-0.49758314, -0.        , -0.49758314, -0.        , -0.49758314,\n",
       "         -0.49758314, -0.        , -0.49758314, -0.        , -0.        ,\n",
       "         -0.49758314, -0.        , -0.        , -0.        , -0.        ,\n",
       "         -0.        , -0.49758314, -0.        , -0.        , -0.49758314,\n",
       "         -0.        , -0.        , -0.        , -0.49758314]),\n",
       "  array([[-0.051016  , -0.        , -0.03645439, -0.        , -0.03854385,\n",
       "          -0.02986771, -0.        , -0.03737504, -0.        , -0.        ,\n",
       "          -0.02509388, -0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        , -0.05390807, -0.        , -0.        , -0.01865564,\n",
       "          -0.        , -0.        , -0.        , -0.04345672],\n",
       "         [ 0.0244058 , -0.        ,  0.02071585, -0.        ,  0.02966948,\n",
       "           0.03270131,  0.        ,  0.01629193,  0.        , -0.        ,\n",
       "           0.03281537, -0.        , -0.        , -0.        , -0.        ,\n",
       "          -0.        ,  0.02478096,  0.        ,  0.        ,  0.02006145,\n",
       "           0.        ,  0.        ,  0.        ,  0.03295628]])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one example\n",
    "gradient = estimateGradientToy(oneHotData[0], k, b, w_vector, V_matrix)\n",
    "print(\"(Label, predicted probability), [beta, w vector, V matrix]:\")\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLossToy(pair):\n",
    "    \"\"\"parallelize log loss\n",
    "        input: ([label, prob], [b_grad, w_grad, v_grad])\n",
    "    \"\"\"\n",
    "    y = pair[0][1]\n",
    "    \n",
    "    eps = 1.0e-16\n",
    "    if pair[0][1] == 0:\n",
    "        p_hat = eps\n",
    "    elif pair[0][1] == 1:\n",
    "        p_hat = 1-eps\n",
    "    else:\n",
    "        p_hat = pair[0][1]\n",
    "    \n",
    "    return float(-(y * np.log(p_hat) + (1-y) * np.log(1-p_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931354980548503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logLossToy(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weight vector W\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03310685],\n",
       "       [ 0.01428775],\n",
       "       [-0.00376144],\n",
       "       [-0.015721  ],\n",
       "       [ 0.02960499],\n",
       "       [ 0.02180846],\n",
       "       [-0.001696  ],\n",
       "       [ 0.01552031],\n",
       "       [-0.01699597],\n",
       "       [-0.01138352],\n",
       "       [ 0.02639799],\n",
       "       [-0.01805496],\n",
       "       [-0.00738271],\n",
       "       [-0.01722051],\n",
       "       [-0.02619963],\n",
       "       [-0.03151945],\n",
       "       [ 0.04281266],\n",
       "       [-0.04104915],\n",
       "       [-0.02042689],\n",
       "       [ 0.01739337],\n",
       "       [ 0.01881405],\n",
       "       [-0.04028339],\n",
       "       [-0.02320497],\n",
       "       [ 0.00714665]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update weights\n",
    "learningRate = 0.1\n",
    "\n",
    "wGrad_reduce = np.zeros((1, numFeats))\n",
    "for r in range(0, nrow):\n",
    "    gradient = estimateGradientToy(oneHotData[r], k, b, w_vector, V_matrix)\n",
    "    wGrad_reduce += gradient[1][1]\n",
    "w_update = wGrad_reduce / nrow\n",
    "\n",
    "w_new = w_vector - learningRate*w_update\n",
    "\n",
    "print(\"New weight vector W\")\n",
    "w_new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New factor matrix V weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01659269, -0.0107129 ],\n",
       "       [-0.00526753, -0.01770845],\n",
       "       [ 0.01061032, -0.01639128],\n",
       "       [ 0.03818184, -0.00625369],\n",
       "       [ 0.00782152, -0.00024604],\n",
       "       [ 0.02496888,  0.00574602],\n",
       "       [ 0.01363172,  0.01560516],\n",
       "       [ 0.01013153, -0.02668518],\n",
       "       [ 0.01761522,  0.00018196],\n",
       "       [-0.06089243, -0.03704973],\n",
       "       [ 0.03440378,  0.00597145],\n",
       "       [ 0.01331686, -0.01696164],\n",
       "       [ 0.02983592, -0.01582817],\n",
       "       [ 0.02259963, -0.04301197],\n",
       "       [ 0.00912995, -0.01519263],\n",
       "       [-0.00842256, -0.00671412],\n",
       "       [-0.02254404, -0.00990762],\n",
       "       [-0.01389515,  0.01140745],\n",
       "       [-0.00252248,  0.00297071],\n",
       "       [ 0.04712819, -0.01923517],\n",
       "       [-0.01277656,  0.01345092],\n",
       "       [ 0.0081833 ,  0.02907576],\n",
       "       [ 0.02244913,  0.00251953],\n",
       "       [-0.00188818,  0.00624993]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update V matrix\n",
    "\n",
    "vGrad_reduce = np.zeros((k, numFeats))\n",
    "for r in range(0, nrow):\n",
    "    gradient = estimateGradientToy(oneHotData[r], k, b, w_vector, V_matrix)\n",
    "    vGrad_reduce += gradient[1][2]\n",
    "v_update = vGrad_reduce / nrow\n",
    "\n",
    "V_new = V_matrix - learningRate*v_update\n",
    "\n",
    "print(\"New factor matrix V weights:\")\n",
    "V_new.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration of Criteo Training Dataset  \n",
    "\n",
    "*Determine 2-3 relevant EDA tasks that will help you make decisions about how you implement the algorithm to be scalable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"w261FinalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`NOTE:`__ Monitor the progress of your jobs using the Spark UI at: http://localhost:4040/jobs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training Data Sample for Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sample contains 4478 rows and 40 columns\n"
     ]
    }
   ],
   "source": [
    "original_trainRDD = sc.textFile('data/train.txt')\n",
    "\n",
    "splits = 0.0001\n",
    "\n",
    "largeRDD, smallTestRDD, smallTrainRDD = original_trainRDD.randomSplit([1-2*splits, splits, splits], seed = 1)\n",
    "smallTrainRDD.cache()\n",
    "\n",
    "ncol = len(smallTrainRDD.take(1)[0].split('\\t'))\n",
    "nrow = smallTrainRDD.count()\n",
    "print(f'This sample contains {nrow} rows and {ncol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions/transformation?/bucketing\n",
    "# correlations\n",
    "# missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distributions\n",
    "# missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization, Dimensionality and Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an average of 33.53 populated features per observation.\n"
     ]
    }
   ],
   "source": [
    "def avgFeatures(line):\n",
    "    count = 0\n",
    "    feats = line.split('\\t')[1:]\n",
    "    for feat in feats:\n",
    "        if feat != '':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"There is an average of\", str(round(smallTrainRDD.map(avgFeatures).mean(),2)), \"populated features per observation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FM Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse raw data and tag feature values with type and feature indices\n",
    "def parseCV(line):\n",
    "    \"\"\"\n",
    "    Map text records to --> (label, features)\n",
    "    Bucket (string) numeric features\n",
    "    Add variable index prefix to feature values for binarization\n",
    "    \"\"\"\n",
    "\n",
    "    # start of categorical features\n",
    "    col_start = 14\n",
    "    \n",
    "    raw_values = line.split('\\t')\n",
    "    label = int(raw_values[0])\n",
    "    \n",
    "    # parse numeric features\n",
    "    numericals = []\n",
    "    for idx, value in enumerate(raw_values[1:col_start]):\n",
    "        if value == '':\n",
    "            append_val = 'NA'\n",
    "        elif value == '0':\n",
    "            append_val = '0'\n",
    "        else:\n",
    "            # continues variables\n",
    "            if idx in [0,3,6,7]:\n",
    "                if float(value)<10:\n",
    "                    append_val = '<10'\n",
    "                elif float(value)<25:\n",
    "                    append_val = '<25'\n",
    "                else:\n",
    "                    append_val = '>25'\n",
    "            elif idx in [1,2,5]:\n",
    "                if float(value)<100:\n",
    "                    append_val = '<100'\n",
    "                else:\n",
    "                    append_val = '>100'\n",
    "            elif idx==4:\n",
    "                if float(value)<10000:\n",
    "                    append_val = '<10k'\n",
    "                elif float(value)<50000:\n",
    "                    append_val = '<50k'\n",
    "                else:\n",
    "                    append_val = '>50k'\n",
    "            elif idx==8:\n",
    "                if float(value)<100:\n",
    "                    append_val = '<100'\n",
    "                elif float(value)<500:\n",
    "                    append_val = '<500'\n",
    "                else:\n",
    "                    append_val = '>500'\n",
    "            elif idx in [10,11]:\n",
    "                if float(value)<3:\n",
    "                    append_val = '<3'\n",
    "                elif float(value)<6:\n",
    "                    append_val = '<6'\n",
    "                else:\n",
    "                    append_val = '>6'\n",
    "            elif idx==12:\n",
    "                if float(value)<5:\n",
    "                    append_val = '<5'\n",
    "                elif float(value)<10:\n",
    "                    append_val = '<10'\n",
    "                elif float(value)<25:\n",
    "                    append_val = '<25'\n",
    "                else:\n",
    "                    append_val = '>25'\n",
    "            # ordinal/binary cases\n",
    "            else:\n",
    "                append_val = str(value)\n",
    "                \n",
    "        numericals.append('n' + str(idx) + '_' + append_val)\n",
    "            \n",
    "    # parse categorical features\n",
    "    categories = []\n",
    "    for idx, value in enumerate(raw_values[col_start:]):\n",
    "        if value == '':\n",
    "            categories.append('c'+ str(idx) + '_NA')\n",
    "        else:\n",
    "            categories.append('c'+ str(idx) + '_' + str(value))\n",
    "\n",
    "    return Row(label=label, raw=numericals + categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call functions\n",
    "parsedDF = smallTrainRDD.map(parseCV).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode All Features using CountVectorizer for Sparse Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to one hot encode all features using a count vectorizer\n",
    "def vectorizeCV(DF):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    cv = CountVectorizer(minDF=1, inputCol=\"raw\", outputCol=\"features\")\n",
    "    \n",
    "    model = cv.fit(DF)\n",
    "    result = model.transform(DF)\n",
    "    \n",
    "    return result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                 raw|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,5...|\n",
      "|    1|[n0_NA, n1_<100, ...|(25739,[0,2,3,4,5...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,4,5,6...|\n",
      "|    1|[n0_<10, n1_<100,...|(25739,[0,1,2,3,4...|\n",
      "|    1|[n0_NA, n1_<100, ...|(25739,[1,2,3,5,6...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,2,5,6...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,5...|\n",
      "|    0|[n0_0, n1_>100, n...|(25739,[0,1,3,4,7...|\n",
      "|    0|[n0_NA, n1_0, n2_...|(25739,[0,2,3,4,8...|\n",
      "|    0|[n0_0, n1_<100, n...|(25739,[0,1,2,4,5...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,2,4,5...|\n",
      "|    0|[n0_NA, n1_>100, ...|(25739,[1,2,3,6,7...|\n",
      "|    0|[n0_0, n1_>100, n...|(25739,[0,1,4,6,8...|\n",
      "|    0|[n0_0, n1_<100, n...|(25739,[0,1,2,5,6...|\n",
      "|    0|[n0_NA, n1_>100, ...|(25739,[1,2,3,6,7...|\n",
      "|    0|[n0_NA, n1_>100, ...|(25739,[0,1,2,3,7...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[1,2,3,5,6...|\n",
      "|    1|[n0_<25, n1_<100,...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_NA, n1_>100, ...|(25739,[0,1,2,3,7...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizedDF, cvModel = vectorizeCV(parsedDF)\n",
    "vectorizedDF.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedRDD = vectorizedDF.select(['label', 'features']).rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total expanded features: 25739\n",
      "Relative frequency of positive class: 0.25949084412684253\n"
     ]
    }
   ],
   "source": [
    "num_feats = vectorizedRDD.take(1)[0][1].size\n",
    "percent_pos = vectorizedRDD.map(lambda x: x[0]).mean()\n",
    "\n",
    "print(\"Number of total expanded features:\", num_feats)\n",
    "print(\"Relative frequency of positive class:\", percent_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictGrad(pair, k_br, b_br, w_br, V_br):\n",
    "    \"\"\"\n",
    "        Compute the predicted probability for average loss AND return the gradients\n",
    "        Args:\n",
    "            pair - records are in (label, sparse feature set) format\n",
    "        Broadcast:\n",
    "            b - bias term (scalar)\n",
    "            w - linear weight vector (array)\n",
    "            k - number of factors (def=2)\n",
    "            V - factor matrix of size (d dimensions, k=2 factors)\n",
    "        Returns:\n",
    "            predRDD - pair of ([label, predicted probability], [set of weight vectors in csr_matrix format])\n",
    "    \"\"\"\n",
    "    \n",
    "    label = pair[0]\n",
    "    feats = pair[1]\n",
    "    \n",
    "    # start with linear weight dot product\n",
    "    linear_sum = np.dot(w_br.value[0][feats.indices], feats.values)\n",
    "\n",
    "    # factor matrix interaction sum\n",
    "    factor_sum = 0.0\n",
    "    lh_factor = [0.0]*k_br.value\n",
    "    rh_factor = [0.0]*k_br.value\n",
    "    \n",
    "    for f in range(0, k_br.value):\n",
    "        lh_factor[f] = np.dot(V_br.value[f][feats.indices], feats.values)  #KEY--this is used in v_grad matrix below\n",
    "        rh_factor[f] = np.dot(V_br.value[f][feats.indices]**2, feats.values**2)\n",
    "        factor_sum += (lh_factor[f]**2 - rh_factor[f])\n",
    "    factor_sum = 0.5 * factor_sum\n",
    "    \n",
    "    pre_prob = b_br.value + linear_sum + factor_sum\n",
    "    \n",
    "    prob = 1.0 / (1 + np.exp(-pre_prob))  #logit transformation\n",
    "    \n",
    "    #compute Gradients\n",
    "    b_grad = prob - label\n",
    "    \n",
    "    w_grad = csr_matrix((b_grad*feats.values, (np.zeros(feats.indices.size), feats.indices)), shape=(1, w_br.value.shape[1]))\n",
    "    \n",
    "    v_data = np.array([], dtype=np.float32)\n",
    "    v_rows = np.array([], dtype=int)\n",
    "    v_cols = np.array([], dtype=int)\n",
    "    for i in range(0, k_br.value):\n",
    "        v_data = np.append(v_data, b_grad*(lh_factor[i]*feats.values - np.multiply(V_br.value[i][feats.indices], feats.values**2)))\n",
    "        v_rows = np.append(v_rows, [i]*feats.indices.size)\n",
    "        v_cols = np.append(v_cols, feats.indices)\n",
    "    v_grad = csr_matrix((v_data, (v_rows, v_cols)), shape=(k_br.value, V_br.value.shape[1]))\n",
    "    \n",
    "    return ([label, prob], [b_grad, w_grad, v_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLoss(pair):\n",
    "    \"\"\"parallelize log-loss calculation\n",
    "        argument: ([label, prob], [b_grad, w_grad, v_grad])\n",
    "        out: -(log-loss)\n",
    "    \"\"\"\n",
    "    y = pair[0][1]\n",
    "    \n",
    "    eps = 1.0e-16\n",
    "    if pair[0][1] == 0:\n",
    "        y_hat = eps\n",
    "    elif pair[0][1] == 1:\n",
    "        y_hat = 1-eps\n",
    "    else:\n",
    "        y_hat = pair[0][1]\n",
    "    \n",
    "    return -(y * np.log(y_hat) + (1-y) * np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceFct(x, y):\n",
    "    \"\"\"function for aggregating bias and weight matrices\n",
    "        arguments: ([label, pred], [bias, weight, V matrix])\n",
    "        out:       [sum bias b, sum weight w, sum matrix V]\n",
    "    \"\"\"\n",
    "    b = x[0] + y[0]\n",
    "    w = x[1] + y[1]\n",
    "    V = x[2] + y[2]\n",
    "    return [b, w, V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateSGD(dataRDD, k, bInit, wInit, vInit, nIter = 2, learningRate = 0.1, useReg = False, regParam = 0.001):\n",
    "\n",
    "    k_br = sc.broadcast(k)    \n",
    "    b_br = sc.broadcast(bInit)\n",
    "    w_br = sc.broadcast(wInit)\n",
    "    V_br = sc.broadcast(vInit)\n",
    "\n",
    "    losses = []\n",
    "    N = dataRDD.count()\n",
    "\n",
    "    for i in range(0, nIter):\n",
    "        print('-' * 25 + 'Iteration ' + str(i+1) + '-' * 25)\n",
    "        predRDD = dataRDD.map(lambda x: predictGrad(x, k_br, b_br, w_br, V_br)).cache()\n",
    "        \n",
    "        loss = predRDD.map(logLoss).reduce(lambda a,b: a+b)/N + \\\n",
    "                int(useReg)*(regParam/2)*(np.linalg.norm(w_br.value)**2 + np.linalg.norm(V_br.value)**2)\n",
    "        losses.append(loss)\n",
    "        print(f'Current log-loss: {loss}')\n",
    "        \n",
    "        # reduce step\n",
    "        gradRDD = predRDD.values().reduce(reduceFct)\n",
    "        bGrad = gradRDD[0]/N\n",
    "        wGrad = gradRDD[1]/N\n",
    "        vGrad = gradRDD[2]/N\n",
    "\n",
    "        print(f\"Bias: {bGrad}\")\n",
    "        print(f\"wGrad shape: {wGrad.shape}\")\n",
    "        print(f\"vGrad shape: {vGrad.shape}\")\n",
    "\n",
    "        ############## update weights ##############\n",
    "        # first, unpersist broadcasts\n",
    "        predRDD.unpersist()\n",
    "        b_br.unpersist()\n",
    "        w_br.unpersist()\n",
    "        V_br.unpersist()\n",
    "\n",
    "        # update and re-broadcast\n",
    "        b_br = sc.broadcast(b_br.value - learningRate * bGrad)\n",
    "        w_br = sc.broadcast(w_br.value - learningRate * (wGrad.toarray()+int(useReg)*regParam*np.linalg.norm(w_br.value)))\n",
    "        V_br = sc.broadcast(V_br.value - learningRate * (vGrad.toarray()+int(useReg)*regParam*np.linalg.norm(V_br.value)))\n",
    "        \n",
    "    return losses, b_br, w_br, V_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Iteration 1-------------------------\n",
      "Current log-loss: 0.6912273009710425\n",
      "Bias: 0.25436576408125167\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 2-------------------------\n",
      "Current log-loss: 0.6851338435935052\n",
      "Bias: 0.18375948102046125\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 3-------------------------\n",
      "Current log-loss: 0.6687666092907115\n",
      "Bias: 0.13441639427762675\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 4-------------------------\n",
      "Current log-loss: 0.6512226506271765\n",
      "Bias: 0.09992019607042654\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 5-------------------------\n",
      "Current log-loss: 0.6356066208636996\n",
      "Bias: 0.07543655596140342\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 6-------------------------\n",
      "Current log-loss: 0.622623423080275\n",
      "Bias: 0.05774713712429709\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 7-------------------------\n",
      "Current log-loss: 0.6121412223222497\n",
      "Bias: 0.04475662909105663\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 8-------------------------\n",
      "Current log-loss: 0.6037891852325022\n",
      "Bias: 0.03508540602284818\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 9-------------------------\n",
      "Current log-loss: 0.5971714200881342\n",
      "Bias: 0.02780504477504894\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "-------------------------Iteration 10-------------------------\n",
      "Current log-loss: 0.5919359790827723\n",
      "Bias: 0.022275786379377382\n",
      "wGrad shape: (1, 25739)\n",
      "vGrad shape: (2, 25739)\n",
      "Performed 10 iterations in 404.480101108551 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialize weights\n",
    "np.random.seed(24)\n",
    "k = 2\n",
    "b = 0.0\n",
    "w = np.random.normal(0.0, 0.02, (1, num_feats))\n",
    "V = np.random.normal(0.0, 0.02, (k, num_feats))\n",
    "\n",
    "# train sample model\n",
    "nIter = 10\n",
    "start = time.time()\n",
    "losses, b_br, w_br, V_br = iterateSGD(vectorizedRDD, k, b, w, V, nIter)\n",
    "print(f'Performed {nIter} iterations in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "x = list(range(1, len(losses)+1))\n",
    "ax.plot(x, losses, 'k--', label='Training Loss')\n",
    "ax.legend(loc='upper right', fontsize='x-large')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.title(\"Log-Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Holdout Development Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictProb(pair, k_br, b_br, w_br, V_br):\n",
    "    \"\"\"\n",
    "        Compute the predicted probability AND return the gradient (?)\n",
    "        Args:\n",
    "            pair - records are in (label, sparse feature set) format\n",
    "        Broadcast:\n",
    "            b - bias term (scalar)\n",
    "            w - linear weight vector (array)\n",
    "            k - number of factors (def=2)\n",
    "            V - factor matrix of size (d dimensions, k=2 factors)\n",
    "        Returns:\n",
    "            predRDD - pair of (label, predicted probability)\n",
    "    \"\"\"\n",
    "    \n",
    "    label = pair[0]\n",
    "    feats = pair[1]\n",
    "    \n",
    "    # start with linear weight dot product\n",
    "    linear_sum = np.dot(w_br.value[0][feats.indices], feats.values)\n",
    "\n",
    "    # factor matrix interaction sum\n",
    "    factor_sum = 0.0\n",
    "    lh_factor = [0.0]*k_br.value\n",
    "    rh_factor = [0.0]*k_br.value\n",
    "    \n",
    "    for f in range(0, k_br.value):\n",
    "        lh_factor[f] = np.dot(V_br.value[f][feats.indices], feats.values)\n",
    "        rh_factor[f] = np.dot(V_br.value[f][feats.indices]**2, feats.values**2)\n",
    "        factor_sum += (lh_factor[f]**2 - rh_factor[f])\n",
    "    factor_sum = 0.5 * factor_sum\n",
    "    \n",
    "    pre_prob = b_br.value + linear_sum + factor_sum\n",
    "    \n",
    "    prob = 1.0 / (1 + np.exp(-pre_prob))  #logit transformation\n",
    "    \n",
    "    return (label, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testLoss(pair):\n",
    "    \"\"\"parallelize log loss\n",
    "        input: (label, prob)\n",
    "    \"\"\"\n",
    "    y = pair[0]\n",
    "    \n",
    "    eps = 1.0e-16\n",
    "    if pair[1] == 0:\n",
    "        y_hat = eps\n",
    "    elif pair[1] == 1:\n",
    "        y_hat = 1-eps\n",
    "    else:\n",
    "        y_hat = pair[1]\n",
    "    \n",
    "    return -(y * np.log(y_hat) + (1-y) * np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss on the hold-out development set is: 0.5588072612641066\n"
     ]
    }
   ],
   "source": [
    "k_br = sc.broadcast(k)\n",
    "\n",
    "parsedTestDF = smallTestRDD.map(parseCV).toDF()\n",
    "vectorizedTestDF = cvModel.transform(parsedTestDF)\n",
    "testLoss = vectorizedTestDF.select(['label', 'features']).rdd \\\n",
    "                                    .map(lambda x: predictProb(x, k_br, b_br, w_br, V_br)) \\\n",
    "                                    .map(testLoss).mean()\n",
    "\n",
    "print(\"Log-loss on the hold-out development set is:\", testLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Unlabeled Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeledRDD = sc.textFile('data/test.txt')\n",
    "scoreTest = 0.001\n",
    "smallUnlabeledRDD = unlabeledRDD.sample(False, scoreTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                 raw|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,4,5,6...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_0, n1_0, n2_<...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[3,5,6,8,1...|\n",
      "|    0|[n0_0, n1_<100, n...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_<10, n1_0, n2...|(25739,[0,1,3,4,8...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,3,5,6...|\n",
      "|    0|[n0_0, n1_<100, n...|(25739,[0,2,4,5,1...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,2,3,4,5...|\n",
      "|    0|[n0_NA, n1_>100, ...|(25739,[1,2,3,6,1...|\n",
      "|    0|[n0_0, n1_0, n2_>...|(25739,[0,1,4,6,9...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[1,2,5,6,7...|\n",
      "|    0|[n0_NA, n1_0, n2_...|(25739,[1,2,3,7,9...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_<25, n1_<100,...|(25739,[0,1,3,4,5...|\n",
      "|    0|[n0_<10, n1_<100,...|(25739,[0,2,3,4,5...|\n",
      "|    0|[n0_NA, n1_<100, ...|(25739,[0,1,2,3,4...|\n",
      "|    0|[n0_<10, n1_0, n2...|(25739,[0,1,2,4,7...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsedUnlabeledDF = smallUnlabeledRDD.map(lambda x: \"0\\t\"+x).map(parseCV).toDF()\n",
    "vectorUnlabeledDF = cvModel.transform(parsedUnlabeledDF)\n",
    "vectorUnlabeledDF.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeledPred = vectorUnlabeledDF.select(['raw','features']).rdd.map(lambda x: predictProb(x, k_br, b_br, w_br, V_br))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['n0_<10',\n",
       "   'n1_<100',\n",
       "   'n2_NA',\n",
       "   'n3_0',\n",
       "   'n4_<10k',\n",
       "   'n5_0',\n",
       "   'n6_<10',\n",
       "   'n7_0',\n",
       "   'n8_0',\n",
       "   'n9_1',\n",
       "   'n10_<3',\n",
       "   'n11_<3',\n",
       "   'n12_0',\n",
       "   'c0_68fd1e64',\n",
       "   'c1_942f9a8d',\n",
       "   'c2_c451a590',\n",
       "   'c3_671f7598',\n",
       "   'c4_25c83c98',\n",
       "   'c5_fbad5c96',\n",
       "   'c6_3f4ec687',\n",
       "   'c7_5b392875',\n",
       "   'c8_a73ee510',\n",
       "   'c9_e113fc4b',\n",
       "   'c10_c4adf918',\n",
       "   'c11_2133afad',\n",
       "   'c12_85dbe138',\n",
       "   'c13_1adce6ef',\n",
       "   'c14_ae97ecc3',\n",
       "   'c15_b47bfaf2',\n",
       "   'c16_3486227d',\n",
       "   'c17_1f868fdd',\n",
       "   'c18_04de9d96',\n",
       "   'c19_b1252a9d',\n",
       "   'c20_3c17ccda',\n",
       "   'c21_NA',\n",
       "   'c22_32c7478e',\n",
       "   'c23_e5fe7725',\n",
       "   'c24_001f3601',\n",
       "   'c25_69a16fdc'],\n",
       "  0.3302264369277568)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeledPred.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model Training on GCP Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Concepts of Machine Learning at Scale  \n",
    "\n",
    "*Pick 3-5 key course concepts and discuss how your work on this assignment illustrates an understanding of these concepts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "441px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "827px",
    "left": "0px",
    "right": "1125px",
    "top": "107px",
    "width": "428px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
